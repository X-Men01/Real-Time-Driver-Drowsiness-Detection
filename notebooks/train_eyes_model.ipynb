{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Below are the libraries and modules used in this project, including libraries for image processing (`PIL`), deep learning (`torch` and `torchvision`), and utilities like `tqdm` for progress bars and `mlflow` for tracking experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision import datasets\n",
    "import torch.multiprocessing as mp\n",
    "from models.cnn_model import Custom_CNN\n",
    "from models.train import training\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import make_grid\n",
    "from utils.utils import display_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Setup\n",
    "\n",
    "Determines the appropriate device for PyTorch operations. The device is chosen based on the availability of CUDA (NVIDIA GPUs) or MPS (Apple Silicon GPUs).\n",
    "If neither is available, it defaults to the CPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    \n",
    "    # else \"mps\" if torch.backends.mps.is_available() \n",
    "    \n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(144, 144), interpolation=InterpolationMode.BILINEAR, max_size=None, antialias=True),\n",
    "    transforms.RandomCrop(size=(128, 128), padding=None),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=[-15.0, 15.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0),\n",
    "    transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.9, 1.1)),\n",
    "    transforms.RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomAutocontrast(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of classes are: {'Close_Eye': 0, 'Open_Eye': 1}\n",
      "\n",
      "Class Names are: ['Close_Eye', 'Open_Eye']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../datasets/processed/Eyes_Dataset\"\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'train'), transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'val'), transform=test_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=test_transforms)\n",
    "\n",
    "\n",
    "class_idx = train_dataset.class_to_idx\n",
    "print(f\"Index of classes are: {class_idx}\")\n",
    "\n",
    "class_names = list(class_idx)\n",
    "print(f\"\\nClass Names are: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = min(4, os.cpu_count())\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True if device == \"cuda\" else False\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True if device == \"cuda\" else False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True if device == \"cuda\" else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_img = next(iter(train_dataloader))[0]\n",
    "# img_grid = make_grid(example_img)\n",
    "# display_images(img_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 10, 128, 128]             100\n",
      "       BatchNorm2d-2         [-1, 10, 128, 128]              20\n",
      "              ReLU-3         [-1, 10, 128, 128]               0\n",
      "            Conv2d-4         [-1, 10, 128, 128]             910\n",
      "       BatchNorm2d-5         [-1, 10, 128, 128]              20\n",
      "              ReLU-6         [-1, 10, 128, 128]               0\n",
      "         MaxPool2d-7           [-1, 10, 64, 64]               0\n",
      "            Conv2d-8           [-1, 20, 64, 64]           1,820\n",
      "       BatchNorm2d-9           [-1, 20, 64, 64]              40\n",
      "             ReLU-10           [-1, 20, 64, 64]               0\n",
      "           Conv2d-11           [-1, 20, 64, 64]           3,620\n",
      "      BatchNorm2d-12           [-1, 20, 64, 64]              40\n",
      "             ReLU-13           [-1, 20, 64, 64]               0\n",
      "        MaxPool2d-14           [-1, 20, 32, 32]               0\n",
      "           Conv2d-15           [-1, 40, 32, 32]           7,240\n",
      "      BatchNorm2d-16           [-1, 40, 32, 32]              80\n",
      "             ReLU-17           [-1, 40, 32, 32]               0\n",
      "           Conv2d-18           [-1, 40, 32, 32]          14,440\n",
      "      BatchNorm2d-19           [-1, 40, 32, 32]              80\n",
      "             ReLU-20           [-1, 40, 32, 32]               0\n",
      "        MaxPool2d-21           [-1, 40, 16, 16]               0\n",
      "           Conv2d-22           [-1, 40, 16, 16]          14,440\n",
      "      BatchNorm2d-23           [-1, 40, 16, 16]              80\n",
      "             ReLU-24           [-1, 40, 16, 16]               0\n",
      "           Conv2d-25           [-1, 40, 16, 16]          14,440\n",
      "      BatchNorm2d-26           [-1, 40, 16, 16]              80\n",
      "             ReLU-27           [-1, 40, 16, 16]               0\n",
      "        MaxPool2d-28             [-1, 40, 8, 8]               0\n",
      "          Flatten-29                 [-1, 2560]               0\n",
      "          Dropout-30                 [-1, 2560]               0\n",
      "           Linear-31                    [-1, 2]           5,122\n",
      "================================================================\n",
      "Total params: 62,572\n",
      "Trainable params: 62,572\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 14.20\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 14.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Custom_CNN(input_shape=1,hidden_units=10,output_shape=len(class_names)).to(device)\n",
    "summary(model, input_size=(1, 128, 128), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-4  \n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_type': 'Custom_CNN', 'optimizer': 'AdamW', 'learning_rate': 0.0003, 'batch_size': 32, 'epochs': 5, 'train_dataset': Dataset ImageFolder\n",
      "    Number of datapoints: 9610\n",
      "    Root location: ../datasets/processed/Eyes_Dataset/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(144, 144), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               RandomCrop(size=(128, 128), padding=None)\n",
      "               Grayscale(num_output_channels=1)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.9, 1.1), hue=None)\n",
      "               RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
      "               RandomAutocontrast(p=0.2)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           ), 'test_dataset': Dataset ImageFolder\n",
      "    Number of datapoints: 2059\n",
      "    Root location: ../datasets/processed/Eyes_Dataset/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )}\n",
      "\u001b[32mModel compiled successfully using torch.compile\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d79ce8937864f65a9889fb1cf6338f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e338200ef64c7fa0e2a6bd2e7819fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m \n",
      "Training interrupted by user!\n",
      "\u001b[31m Error during cleanup: Error(s) in loading state_dict for OptimizedModule:\n",
      "\tsize mismatch for _orig_mod.conv_block_1.0.weight: copying a param with shape torch.Size([10, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([10, 1, 3, 3]).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    results = training(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        early_stopping_patience=5,\n",
    "        experiment_name=\"EyeClassifier_v1\"\n",
    "        \n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\033[33m Training interrupted by user!\")\n",
    "finally:\n",
    "    # Cleanup\n",
    "    for dataloader in [train_dataloader, val_dataloader, test_dataloader]:\n",
    "        if hasattr(dataloader, '_iterator') and dataloader._iterator is not None:\n",
    "            dataloader._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Compose' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_transforms\u001b[38;5;241m.\u001b[39mdataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Compose' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "test_transforms.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
